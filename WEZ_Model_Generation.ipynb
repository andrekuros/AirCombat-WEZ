{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc38d15a",
   "metadata": {},
   "source": [
    "# WEZ Model Generation\n",
    "This notebook implements the pipeline for Weapon Engagement Zone (WEZ) model generation from the paper:\n",
    "\n",
    "Optimized Prediction of Weapon Effectiveness in BVR Air Combat Scenarios Using Enhanced Regression Models\n",
    "\n",
    "\n",
    "## Objectives\n",
    "- Develop and evaluate WEZ models using data from experiments.\n",
    "- Compare the performance of multiple regression techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c97e6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required Libraries\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import time\n",
    "import itertools\n",
    "import time\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, PolynomialFeatures\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_squared_log_error \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet \n",
    "\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import  RandomForestRegressor\n",
    "\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\n",
    "from sklearn.gaussian_process.kernels import DotProduct, WhiteKernel\n",
    "\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9ca649e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareDataFromASA(fileName, R = True,\\\n",
    "                        Da = True, size = -1,  \\\n",
    "                        T = True, multiObj = False, rangeType = \"WEZ\"):\n",
    "        \n",
    "    fulldataDf = pd.read_csv(fileName)   \n",
    "    \n",
    "    if size > 0:\n",
    "        fulldataDf = fulldataDf.sample(size)\n",
    "        \n",
    "    dataDf = fulldataDf[['BL_Speed', 'RD_Speed', 'rad', 'RD_Hdg', 'BL_Alt', 'RD_Alt']]\n",
    "    \n",
    "    if not multiObj:\n",
    "        dataDf[rangeType] = fulldataDf[rangeType].replace(-1,0)        \n",
    "        dataDf = dataDf[dataDf[rangeType] >= 2] \n",
    "    else:\n",
    "        dataDf['RNez'] = fulldataDf['RNez'].replace(-1,0)                \n",
    "        dataDf['RMax'] = fulldataDf['RMax'].replace(-1,0)                \n",
    "        dataDf = dataDf[dataDf['RNez'] >= 2]         \n",
    "        dataDf = dataDf[dataDf['RMax'] >= 2] \n",
    "\n",
    "    \n",
    "    if Da:                \n",
    "        \n",
    "        dataDf_Arg = dataDf.copy()\n",
    "        dataDf_Arg['rad'] = dataDf_Arg.apply(lambda x: -1 * x.rad , axis=1)  \n",
    "        dataDf_Arg['RD_Hdg'] = dataDf_Arg.apply(lambda x: -1 * x.RD_Hdg , axis=1)         \n",
    "        dataDf = pd.concat([dataDf, dataDf_Arg], axis=0, ignore_index=True)        \n",
    "            \n",
    "    dataDf['diffAlt'] = dataDf.apply(lambda x: x.BL_Alt - x.RD_Alt, axis=1)      \n",
    "                \n",
    "    if R:        \n",
    "        dataDf['relRedHdg'] = dataDf.apply(lambda x: (x.RD_Hdg-x.rad) , axis=1) \n",
    "        if T:\n",
    "            dataDf['cosRel'] = dataDf.apply(lambda x: math.cos(x.relRedHdg*math.pi/180), axis=1)\n",
    "            dataDf['sinRel'] = dataDf.apply(lambda x: math.sin(x.relRedHdg*math.pi/180), axis=1) \n",
    "            dataDf = dataDf.drop(['relRedHdg'], axis=1)              \n",
    "    \n",
    "    else:     \n",
    "        dataDf['relRedHdg'] = dataDf.apply(lambda x: 0-x.RD_Hdg , axis=1)\n",
    "        if T:\n",
    "            dataDf['cosRel'] = dataDf.apply(lambda x: math.cos(x.relRedHdg*math.pi/180), axis=1)\n",
    "            dataDf['sinRel'] = dataDf.apply(lambda x: math.sin(x.relRedHdg*math.pi/180), axis=1)\n",
    "            dataDf['cosRel2'] = dataDf.apply(lambda x: math.cos(x.rad*math.pi/180), axis=1)\n",
    "            dataDf['sinRel2'] = dataDf.apply(lambda x: math.sin(x.rad*math.pi/180), axis=1)\n",
    "            dataDf = dataDf.drop(['relRedHdg'], axis=1)  \n",
    "            #dataDf = dataDf.drop(['rad'], axis =1)                                                          \n",
    "    \n",
    "    dataDf = dataDf.drop(['RD_Hdg'], axis =1)     \n",
    "    dataDf = dataDf.drop(['RD_Alt'], axis =1) \n",
    "        \n",
    "    return dataDf\n",
    "\n",
    "\n",
    "    \"\"\"Select and initialize a regression model based on its name.\n",
    "\n",
    "    Args:\n",
    "        name (str): The name identifier for the regression model.\n",
    "\n",
    "    Returns:\n",
    "        model: An instance of a regression model.\n",
    "    \"\"\"\n",
    "    if name == \"SVR_Poly\":\n",
    "        return SVR(kernel=\"poly\", C=5000, gamma=\"auto\", degree=1, epsilon=0.1, max_iter=50000000, coef0=0)\n",
    "    elif name == \"SVR_RBF\":\n",
    "        return SVR(kernel=\"rbf\", C=5000, gamma=\"auto\", epsilon=0.1)\n",
    "    elif name == \"SVR_Linear\":\n",
    "        return SVR(kernel=\"linear\", C=5000, gamma=\"auto\", epsilon=0.1)\n",
    "    elif name == \"MLP\":\n",
    "        return MLPRegressor(random_state=1, max_iter=500000, activation='tanh', hidden_layer_sizes=(128, 128), alpha=0.0001, solver='adam')\n",
    "    elif name == \"MLP32\":\n",
    "        return MLPRegressor(random_state=1, max_iter=500000, activation='tanh', hidden_layer_sizes=(32, 32), alpha=0.0001, solver='adam')\n",
    "    elif name == \"MLP128\":\n",
    "        return MLPRegressor(random_state=1, max_iter=500000, activation='tanh', hidden_layer_sizes=(128, 128), alpha=0.0001, solver='adam')\n",
    "    elif name == \"MLP256\":\n",
    "        return MLPRegressor(random_state=1, max_iter=500000, activation='tanh', hidden_layer_sizes=(256, 256), alpha=0.0001, solver='adam')\n",
    "    elif name == \"LinReg\":\n",
    "        return LinearRegression(n_jobs=15, fit_intercept=False)\n",
    "    elif name == 'Lasso':\n",
    "        return Lasso(alpha=0.00025)\n",
    "    elif name == 'Ridge':\n",
    "        return Ridge(alpha=0.02)\n",
    "    elif name == 'ElasticNet':\n",
    "        return ElasticNet(alpha=0.00025, l1_ratio=0.5)\n",
    "    elif name == \"RF\":\n",
    "        return RandomForestRegressor(n_estimators=70, random_state=1, max_depth=20, n_jobs=10)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown Model: {name}\")\n",
    "\n",
    "def split_train_test(X, Y, mode, fold, trainingSize, testSize, dataSplitRatio, DataSetTest=None):\n",
    "    \"\"\"\n",
    "    Splits the data into training and testing sets based on the mode.\n",
    "\n",
    "    Parameters:\n",
    "        X (pd.DataFrame): Features.\n",
    "        Y (pd.DataFrame): Target.\n",
    "        mode (str): Split mode (RandomSplit, AlternateTest, FixedTestSize).\n",
    "        fold (int): Current fold index.\n",
    "        trainingSize (int): Size of training data.\n",
    "        testSize (int): Size of testing data.\n",
    "        dataSplitRatio (float): Ratio for RandomSplit.\n",
    "        DataSetTest (pd.DataFrame, optional): Alternate test dataset.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (X_train, X_test, Y_train, Y_test)\n",
    "    \"\"\"\n",
    "    if mode == \"RandomSplit\":\n",
    "        return train_test_split(X, Y, test_size=dataSplitRatio, random_state=fold)\n",
    "    elif mode == \"AlternateTest\":\n",
    "        X_train = X[:trainingSize]\n",
    "        Y_train = Y[:trainingSize]\n",
    "        shuffled_test = shuffle(DataSetTest, random_state=fold)\n",
    "        X_test = shuffled_test.drop([\"maxRange\"], axis=1)[:600]\n",
    "        Y_test = shuffled_test.maxRange[:600]\n",
    "        return X_train, X_test, Y_train, Y_test\n",
    "    elif mode == \"FixedTestSize\":\n",
    "        return train_test_split(X, Y, test_size=testSize, train_size=trainingSize, random_state=fold)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported split mode: {mode}\")\n",
    "\n",
    "# Function to get a specific regressor based on its name\n",
    "def get_regressor(name, fold, multi_obj=False):\n",
    "    \"\"\"\n",
    "    Returns the specified regression model with appropriate parameters.\n",
    "    \"\"\"\n",
    "    if name == \"MLP32\":\n",
    "        return MLPRegressor(random_state=fold, max_iter=500000, activation='tanh', hidden_layer_sizes=(32, 32))\n",
    "    elif name == \"MLP128\":\n",
    "        return MLPRegressor(random_state=fold, max_iter=500000, activation='tanh', hidden_layer_sizes=(128, 128))\n",
    "    elif name == \"MLP256\":\n",
    "        return MLPRegressor(random_state=fold, max_iter=500000, activation='tanh', hidden_layer_sizes=(256, 256))\n",
    "    elif name == \"Ridge\":\n",
    "        return Ridge(alpha=0.02)\n",
    "    elif name == \"Lasso\":\n",
    "        return Lasso(alpha=0.00025)\n",
    "    elif name == \"ElasticNet\":\n",
    "        return ElasticNet(alpha=0.00025, l1_ratio=0.5)\n",
    "    elif name == \"RF\":\n",
    "        return RandomForestRegressor(n_estimators=50, max_depth=20, random_state=fold, n_jobs=10)\n",
    "    elif name == \"LinReg\":\n",
    "        return LinearRegression(n_jobs=15, fit_intercept=False)\n",
    "    elif name == \"SVR_Poly\":\n",
    "        svr = SVR(kernel=\"poly\", C=5000, gamma=\"auto\", degree=1, epsilon=0.1, max_iter=50000000)\n",
    "        return MultiOutputRegressor(svr) if multi_obj else svr\n",
    "    elif name == \"SVR_RBF\":\n",
    "        svr = SVR(kernel=\"rbf\", C=5000, gamma=\"auto\", epsilon=0.1)\n",
    "        return MultiOutputRegressor(svr) if multi_obj else svr\n",
    "    elif name == \"SVR_Linear\":\n",
    "        svr = SVR(kernel=\"linear\", C=5000, gamma=\"auto\", epsilon=0.1)\n",
    "        return MultiOutputRegressor(svr) if multi_obj else svr\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown Model: {name}\")\n",
    "\n",
    "def perform_feature_reduction(X_trainS, X_testS, model, polyReductionFactors, regressor, powers, Y_train):\n",
    "    \"\"\"\n",
    "    Reduces features based on model coefficients.\n",
    "\n",
    "    Parameters:\n",
    "        X_trainS (pd.DataFrame): Training dataset with features.\n",
    "        X_testS (pd.DataFrame): Test dataset with features.\n",
    "        model: Trained model with accessible coefficients.\n",
    "        polyReductionFactors (int): Number of features to retain.\n",
    "        regressor (str): Type of regressor (e.g., \"Ridge\", \"Lasso\").\n",
    "        powers (np.ndarray): Powers of polynomial features.\n",
    "        Y_train (pd.DataFrame): Target variable for training.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (X_train_reduced, X_test_reduced, effects, updated_powers)\n",
    "    \"\"\"\n",
    "    effects = []\n",
    "\n",
    "    if polyReductionFactors > 0:\n",
    "        # Extract coefficients based on the model type\n",
    "        if regressor == \"Ridge\":\n",
    "            coefs = model.coef_[0]\n",
    "        elif regressor == \"Lasso\":\n",
    "            coefs = model.coef_\n",
    "        else:\n",
    "            print(f\"Error: Model {regressor} does not accept parameters reduction\")\n",
    "            exit(1)\n",
    "        \n",
    "        # Pair features with coefficients and sort by importance\n",
    "        coefsAux = [[X_trainS.columns[i], c] for i, c in enumerate(list(coefs))]\n",
    "        coefsAux = sorted(coefsAux, key=lambda x: -abs(x[1]))\n",
    "\n",
    "        if coefsAux:\n",
    "            # Identify insignificant features to drop\n",
    "            insig = [x[0] for x in coefsAux[polyReductionFactors:]]\n",
    "            totalCoefs = sum([abs(x[1]) for x in coefsAux])\n",
    "\n",
    "            # Record effects for the remaining features\n",
    "            dictEf = {\"total\": totalCoefs}\n",
    "            for x in coefsAux:\n",
    "                dictEf[x[0]] = x[1] / totalCoefs\n",
    "            effects.append(dictEf)\n",
    "\n",
    "            # Drop insignificant features\n",
    "            X_trainS = X_trainS.drop(insig, axis=1)\n",
    "            X_testS = X_testS.drop(insig, axis=1)\n",
    "\n",
    "            # Update powers\n",
    "            mask = np.ones(powers.shape[0], dtype=bool)\n",
    "            mask[insig] = False\n",
    "            powers = powers[mask]\n",
    "\n",
    "            # Refit the model on reduced features\n",
    "            model.fit(X_trainS, Y_train)\n",
    "\n",
    "            # Recompute coefficients and effects after reduction\n",
    "            if regressor == \"Ridge\":\n",
    "                coefs = model.coef_[0]\n",
    "            elif regressor == \"Lasso\":\n",
    "                coefs = model.coef_\n",
    "\n",
    "            coefsAux = [[X_trainS.columns[i], c] for i, c in enumerate(list(coefs))]\n",
    "            coefsAux = sorted(coefsAux, key=lambda x: -abs(x[1]))\n",
    "            totalCoefs = sum([abs(x[1]) for x in coefsAux])\n",
    "\n",
    "            dictEf = {\"total\": totalCoefs}\n",
    "            for x in coefsAux:\n",
    "                dictEf[x[0]] = x[1] / totalCoefs\n",
    "            effects.append(dictEf)\n",
    "        else:\n",
    "            print(\"Fail to Reduce Params\")\n",
    "            exit(1)\n",
    "\n",
    "    return X_trainS, X_testS, effects, powers\n",
    "\n",
    "def print_configuration_summary(rangeType, dataFile, testSplitMode, trainingSize, testSize, \n",
    "                                 dataSplitRatio, multi_obj, out_vars, models_config, data_preprocess, normalize, \n",
    "                                 proccess_combinations):\n",
    "    \"\"\"\n",
    "    Prints a detailed summary of the experiment configuration.\n",
    "    \n",
    "    Parameters:        \n",
    "        rangeType (str): Range type for the experiment.\n",
    "        dataFile (str): Dataset file name.\n",
    "        testSplitMode (str): Mode of splitting the dataset.\n",
    "        trainingSize (int): Number of training samples.\n",
    "        testSize (int): Number of test samples.\n",
    "        dataSplitRatio (float): Ratio of data splitting for random split.\n",
    "        multi_obj (bool): Indicates if the task is multi-objective.\n",
    "        out_vars (list): Output variables for prediction.\n",
    "        models_config (dict): Model configurations.\n",
    "        data_preprocess (dict): Data preprocessing configurations.\n",
    "        normalize (bool): Whether all features should be normalized.\n",
    "        proccess_combinations (list): List of preprocessing combinations.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"                Experiment Configuration Summary\")\n",
    "    print(\"=\"*50)    \n",
    "    print(f\"Range Type                 : {rangeType}\")\n",
    "    print(f\"Dataset File               : {dataFile}\")\n",
    "    print(f\"Test Split Mode            : {testSplitMode}\")\n",
    "    \n",
    "    if testSplitMode == \"RandomSplit\":\n",
    "        print(f\"Data Split Ratio           : {dataSplitRatio:.2f}\")\n",
    "    else:\n",
    "        print(f\"Training Set Size          : {trainingSize}\")\n",
    "        print(f\"Test Set Size              : {testSize}\")\n",
    "        \n",
    "    print(f\"Multi-Objective            : {multi_obj}\")\n",
    "    print(f\"Output Variables           : {', '.join(out_vars)}\")\n",
    "    print(\"\\nModel Configurations:\")\n",
    "    print(f\"  Interaction Degrees      : {models_config['interactionsDegrees']}\")\n",
    "    print(f\"  Reduction Factors        : {models_config['reductionsFactors']}\")\n",
    "    print(f\"  Number of Folds          : {models_config['folds']}\")\n",
    "    print(f\"  Selected Regressors      : {', '.join(models_config['regressors'])}\")\n",
    "    print(\"\\nPreprocessing Configurations:\")\n",
    "    for key, values in data_preprocess.items():\n",
    "        print(f\"  {key:20}: {values}\")\n",
    "    print(f\"\\nNormalize Features     : {normalize}\")\n",
    "    print(f\"Total Preprocessing Combos : {len(proccess_combinations)}\")\n",
    "    print(\"=\"*50 + \"\\n\")\n",
    "\n",
    "def bootstrap_ci(data, metric, n_bootstrap=5000, max_iterations=1000, min_variation=0.00001):\n",
    "    bootstrap_samples = []\n",
    "    prev_ci_lower, prev_ci_upper = None, None\n",
    "    \n",
    "    for i in range(max_iterations):\n",
    "        bootstrap_sample = np.random.choice(data[metric], size=len(data), replace=True)\n",
    "        bootstrap_samples.append(np.mean(bootstrap_sample))\n",
    "        \n",
    "        ci_lower, ci_upper = np.percentile(bootstrap_samples, [2.5, 97.5])\n",
    "        \n",
    "        if prev_ci_lower is not None and prev_ci_upper is not None:\n",
    "            variation = max(abs(ci_lower - prev_ci_lower), abs(ci_upper - prev_ci_upper))\n",
    "            if variation < min_variation:\n",
    "                break\n",
    "        \n",
    "        prev_ci_lower, prev_ci_upper = ci_lower, ci_upper\n",
    "    \n",
    "    return (ci_lower, ci_upper)\n",
    "\n",
    "def evalData(regressor, output_vars, ref_vel, X, Y,  timeReps = 100):\n",
    "    \n",
    "    #Eval on Training set\n",
    "    start = time.time()\n",
    "    \n",
    "    for i in range(timeReps):\n",
    "        y_pred = regressor.predict(X)     \n",
    "    predTime = time.time() - start  \n",
    "    \n",
    "    eval_results = {}   \n",
    "    \n",
    "    for i, output_name in enumerate(output_vars):\n",
    "        \n",
    "        Y_item  = np.array(Y[output_name])                \n",
    "        \n",
    "        if len(output_vars) > 1:\n",
    "            y_pred_item = np.array(y_pred[:,i])\n",
    "        else:\n",
    "            y_pred_item = np.array(y_pred).flatten()\n",
    "                    \n",
    "        \n",
    "        predDiff = Y_item - y_pred_item        \n",
    "        maxError = max( abs(predDiff)) \n",
    "        \n",
    "        if isinstance(ref_vel, np.ndarray):                    \n",
    "            time_err = np.mean(abs((predDiff) / ref_vel))\n",
    "        else:\n",
    "            time_err = np.mean(abs((predDiff) / 550))\n",
    "            \n",
    "        rel_err =  np.mean(abs((predDiff) / Y_item))               \n",
    "        mae = mean_absolute_error(Y_item, y_pred_item)\n",
    "        rmse = math.sqrt(mean_squared_error(Y_item, y_pred_item)) \n",
    "        \n",
    "        eval_results.update({output_name + \"_MAE\" : mae, \n",
    "                             output_name + \"_RMSE\" : rmse,\n",
    "                             output_name + \"_time_err\": time_err,\n",
    "                             output_name + \"_relative_err\" : rel_err,                             \n",
    "                             output_name + \"_max_error\" :maxError})\n",
    "    \n",
    "    eval_results['MAE']  = mean_absolute_error(Y, y_pred)    \n",
    "    eval_results['RMSE'] = math.sqrt(mean_squared_error(Y, y_pred)) \n",
    "    eval_results['MAPE'] =  np.mean(abs((predDiff) / Y_item))   \n",
    "        \n",
    "    eval_results.update({\"pred_time\" : predTime/len(Y) * 1000 , \"eval_reps\" : timeReps} )\n",
    "\n",
    "    return (y_pred, eval_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36711a6b",
   "metadata": {},
   "source": [
    "# Experiment Configuration\n",
    "\"\"\"\n",
    "## Experiment Configuration\n",
    "\n",
    "This section defines all the parameters required for the experiment. \n",
    "\n",
    "### Key Sections:\n",
    "1. **Experiment Tag and Range Type**:   \n",
    "   - `rangeType`: Specifies the output range to be modeled. Options include:\n",
    "     - `RMax`: Maximum range.\n",
    "     - `RNez`: No Escape Zone range.\n",
    "     - `Wez`: Multi-Objective Model for both Ranges\n",
    "\n",
    "2. **Data Splitting Parameters**:\n",
    "   - `testSplitMode`: Determines how the dataset is divided into training and testing sets. Options:\n",
    "     - `FixedTestSize`: Fixed number of training and test samples.\n",
    "     - `RandomSplit`: Randomly splits data based on a specified ratio.\n",
    "     - `AlternateTest`: Uses an alternate dataset for testing.\n",
    "   - `trainingSize` and `testSize`: Define the sizes of training and test datasets (applicable for `FixedTestSize`).\n",
    "   - `dataSplitRatio`: Ratio for splitting data (used for `RandomSplit` mode).\n",
    "\n",
    "3. **Normalization**:\n",
    "   - If `normalize` is `True`, the features will be normalized (scaled) to improve model performance.\n",
    "\n",
    "4. **Model Configuration**:\n",
    "   - Includes options for:\n",
    "     - Polynomial interaction degrees (`interactionsDegrees`).\n",
    "     - Feature reduction factors (`reductionsFactors`).\n",
    "     - Number of folds for cross-validation (`folds`).\n",
    "     - List of regressors to evaluate (`regressors`).\n",
    "         - \"Lasso\", \"Ridge\", \"ElasticNet\", \"LinReg\",\\\n",
    "           \"MLP32\", \"MLP128\", \"MLP256\",\\\n",
    "            \"SVR_RBF\", \"SVR_Poly\", \"SVR_Linear\"\\\n",
    "            \"RF\"\n",
    "\n",
    "5. **Data Preprocessing Options**:\n",
    "   - Configures preprocessing:\n",
    "     - (R)  Adding relative red heading features (`relativeRedHdg`).\n",
    "     - (Da) Augmenting the dataset (`argumentation`).\n",
    "     - (T)  Applying sine and cosine transformations to angular features (`sinCos`).\n",
    "\n",
    "6. **Test Parameters**:\n",
    "   - Reserved for custom testing or advanced configurations.\n",
    "\n",
    "---\n",
    "\n",
    "### How to Use:\n",
    "1. Modify the values in the configuration block below to customize the experiment.\n",
    "2. Ensure the selected options align with your dataset and goals.\n",
    "3. Once the configuration is set, proceed to the model training and evaluation steps.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "affde406",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Experiment identification\n",
    "runTag = \"Test01\"\n",
    "\n",
    "# Range Type\n",
    "rangeType = \"RMax\"  # Specifies the type of output range to model (e.g., \"RMax\", \"RNez\", \"Wez\").\n",
    "\n",
    "# Data Splitting Configuration\n",
    "testSplitMode = \"FixedTestSize\" # Mode of splitting the data:\n",
    "                                # - \"FixedTestSize\": Fixed training and test sizes.\n",
    "                                # - \"RandomSplit\": Random split with a specified ratio.\n",
    "                                # - \"AlternateTest\": Use alternate dataset for testing.\n",
    "\n",
    "trainingSize = 700               # Number of samples in the training dataset (applicable for FixedTestSize).\n",
    "testSize = 200                   # Number of samples in the testing dataset (applicable for FixedTestSize).\n",
    "dataSplitRatio = 0.20            # Ratio for splitting data (applicable for RandomSplit).\n",
    "\n",
    "# Normalization Flag\n",
    "normalize = True  # Whether to normalize all features (MinMaxScaler or StandardScaler can be used later).\n",
    "\n",
    "# Model Configuration\n",
    "models_config = { \n",
    "    'interactionsDegrees': [5,6],             # Polynomial interaction degrees to explore.\n",
    "    'reductionsFactors': [100],             # Number of features to retain after reduction.\n",
    "    'folds': 1,                             # Number of folds for cross-validation.\n",
    "    'regressors': [\"Lasso\", \"Ridge\"],       # List of regression models to evaluate. Examples:\n",
    "                                 \n",
    "}\n",
    "\n",
    "# Data Preprocessing Options\n",
    "data_preprocess = {        \n",
    "    'R' :  [True, False],   # Whether to include relative heading \n",
    "    'Da':  [True],   # Whether to augment the dataset \n",
    "    'T' :  [True],   # Whether to include sine and cosine transformations of angular data.\n",
    "} \n",
    "\n",
    "# Test Parameters\n",
    "test_params = [-1]  # Additional parameters to pass for testing specific configurations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b967861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "                Experiment Configuration Summary\n",
      "==================================================\n",
      "Range Type                 : RMax\n",
      "Dataset File               : RandomExperiment_1000_RMAX.csv\n",
      "Test Split Mode            : FixedTestSize\n",
      "Training Set Size          : 700\n",
      "Test Set Size              : 200\n",
      "Multi-Objective            : False\n",
      "Output Variables           : RMax\n",
      "\n",
      "Model Configurations:\n",
      "  Interaction Degrees      : [5, 6]\n",
      "  Reduction Factors        : [100]\n",
      "  Number of Folds          : 1\n",
      "  Selected Regressors      : Lasso, Ridge\n",
      "\n",
      "Preprocessing Configurations:\n",
      "  R                   : [True, False]\n",
      "  Da                  : [True]\n",
      "  T                   : [True]\n",
      "\n",
      "Normalize Features     : True\n",
      "Total Preprocessing Combos : 2\n",
      "==================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_119812\\1811493729.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataDf[rangeType] = fulldataDf[rangeType].replace(-1,0)\n",
      "c:\\Programas\\b_ace_env\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.263e+01, tolerance: 6.176e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- (1/1) RMax | Lasso | IntDeg(5) | preProc(RTDa) | Reduct(100) ---"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 108\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m     92\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[38;5;124m--- (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodels_config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfolds\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrangeType\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     93\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mregressor\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    102\u001b[0m     end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    103\u001b[0m )\n\u001b[0;32m    107\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m polyReductionFactors \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 108\u001b[0m     X_trainS, X_testS, effects, powers \u001b[38;5;241m=\u001b[39m \u001b[43mperform_feature_reduction\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    109\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX_trainS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_testS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpolyReductionFactors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mregressor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpowers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_train\u001b[49m\n\u001b[0;32m    110\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    112\u001b[0m y_pred, eval_data \u001b[38;5;241m=\u001b[39m evalData(pipeline, out_vars, np\u001b[38;5;241m.\u001b[39marray(pd\u001b[38;5;241m.\u001b[39mDataFrame(X_test\u001b[38;5;241m.\u001b[39mBL_Speed)), X_testS, Y_test )\n\u001b[0;32m    114\u001b[0m test_data \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m                 : \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest_Data\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[0;32m    115\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mregressor\u001b[39m\u001b[38;5;124m\"\u001b[39m             : regressor,\n\u001b[0;32m    116\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpreprocess_params\u001b[39m\u001b[38;5;124m\"\u001b[39m     : params,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    120\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining_size\u001b[39m\u001b[38;5;124m\"\u001b[39m         : trainingSize\n\u001b[0;32m    121\u001b[0m             }\n",
      "Cell \u001b[1;32mIn[2], line 201\u001b[0m, in \u001b[0;36mperform_feature_reduction\u001b[1;34m(X_trainS, X_testS, model, polyReductionFactors, regressor, powers, Y_train)\u001b[0m\n\u001b[0;32m    198\u001b[0m X_testS \u001b[38;5;241m=\u001b[39m X_testS\u001b[38;5;241m.\u001b[39mdrop(insig, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    200\u001b[0m \u001b[38;5;66;03m# Update powers\u001b[39;00m\n\u001b[1;32m--> 201\u001b[0m mask \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241m.\u001b[39mones(powers\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mbool\u001b[39m)\n\u001b[0;32m    202\u001b[0m mask[insig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    203\u001b[0m powers \u001b[38;5;241m=\u001b[39m powers[mask]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "metricsSummary = []\n",
    "\n",
    "proccess_combinations = list(itertools.product(*data_preprocess.values()))\n",
    "\n",
    "if rangeType == \"RMax\":    \n",
    "    dataFile = \"RandomExperiment_1000_RMAX.csv\"     \n",
    "    multi_obj = False\n",
    "    out_vars = ['RMax']\n",
    "elif rangeType == \"RNez\":\n",
    "    dataFile = \"RandomExperiment_1000_NEZ.csv\"     \n",
    "    multi_obj = False\n",
    "    out_vars = ['RNez']\n",
    "elif rangeType == \"Wez\":\n",
    "    dataFile = \"RandomExperiment_1000_WEZ.csv\"     \n",
    "    multi_obj = True\n",
    "    out_vars = ['RNez','RMax']\n",
    "\n",
    "# Print summary of configurations\n",
    "print_configuration_summary(    \n",
    "    rangeType=rangeType,\n",
    "    dataFile=dataFile,\n",
    "    testSplitMode=testSplitMode,\n",
    "    trainingSize=trainingSize,\n",
    "    testSize=testSize,\n",
    "    dataSplitRatio=dataSplitRatio,\n",
    "    multi_obj=multi_obj,\n",
    "    out_vars=out_vars,\n",
    "    models_config=models_config,\n",
    "    data_preprocess=data_preprocess,\n",
    "    normalize=normalize,\n",
    "    proccess_combinations=proccess_combinations\n",
    ")\n",
    "\n",
    "for params in proccess_combinations:\n",
    "    \n",
    "    config = dict(zip(data_preprocess.keys(), params))        \n",
    "    dataSet = prepareDataFromASA('./Data/' + dataFile, multiObj=multi_obj, rangeType = rangeType, **config)        \n",
    "    \n",
    "    for regressor in models_config['regressors']:       \n",
    "        for interactionsDegree in models_config['interactionsDegrees']:\n",
    "            for polyReductionFactors in models_config['reductionsFactors']:                \n",
    "                for it, test_param in enumerate(test_params):\n",
    "                                    \n",
    "                    metricsTest = []                    \n",
    "                    \n",
    "                    for fold in range(models_config['folds']):\n",
    "                        \n",
    "                        if not multi_obj:\n",
    "                            X = dataSet.drop([rangeType], axis=1)\n",
    "                            Y = dataSet[[rangeType]]\n",
    "                        else:\n",
    "                            X = dataSet.drop([\"RNez\", \"RMax\"], axis=1)\n",
    "                            Y = dataSet[[\"RNez\", \"RMax\"]]                                                                            \n",
    "                        \n",
    "                        \n",
    "                        X_train, X_test, Y_train, Y_test = split_train_test(\n",
    "                            X, Y, testSplitMode, fold, trainingSize, testSize, dataSplitRatio\n",
    "                        )                       \n",
    "                        \n",
    "                        X_trainS = X_train                    \n",
    "                        X_testS = X_test                    \n",
    "                                                                                    \n",
    "                        # Create interaction terms (interaction of each regressor pair + polynomial)                        \n",
    "                        if interactionsDegree > 1:\n",
    "                            if regressor == \"LinReg\" or regressor == \"Lasso\" or regressor == \"Ridge\" or regressor == \"ElasticNet\":                            \n",
    "                                interaction = PolynomialFeatures(degree=interactionsDegree, include_bias=False, interaction_only=False)                                                  \n",
    "                                X_trainS = pd.DataFrame(interaction.fit_transform(X_trainS), columns=interaction.get_feature_names_out(input_features=list(map(str,list(X_trainS.columns)))))   \n",
    "                                X_testS = pd.DataFrame(interaction.fit_transform(X_testS), columns=interaction.get_feature_names_out(input_features=list(map(str,list(X_testS.columns)))))\n",
    "                                powers = interaction.powers_\n",
    "                                cols = X_trainS.columns                                                           \n",
    "\n",
    "                        if normalize:\n",
    "                            #scaler = StandardScaler()  \n",
    "                            scaler = MinMaxScaler()\n",
    "                            scaler.fit_transform(X_trainS)                            \n",
    "                            X_trainS = scaler.transform(X_trainS)    \n",
    "                            X_testS = scaler.transform(X_testS)                                            \n",
    "                            X_trainS = pd.DataFrame(X_trainS)\n",
    "                            X_testS = pd.DataFrame(X_testS)\n",
    "                        else:\n",
    "                            X_trainS = pd.DataFrame(X_trainS.values)\n",
    "                            X_testS  = pd.DataFrame(X_testS.values)\n",
    "                                                                                                                            \n",
    "                        model = get_regressor(regressor, fold, multi_obj)                        \n",
    "                                \n",
    "                        pipeline = Pipeline([('model', model)])                        \n",
    "                        start = time.time()                                                            \n",
    "                        pipeline.fit(X_trainS,Y_train)                    \n",
    "                        fitTime = time.time() - start\n",
    "                        \n",
    "                        print(\n",
    "                            f'\\r--- ({fold+1}/{models_config[\"folds\"]}) {rangeType} | '\n",
    "                            f'{regressor} | '\n",
    "                            f'IntDeg({interactionsDegree}) | '                            \n",
    "                            f'{(\"TestParam(\" + str(test_param) + \") | \") if test_param != -1 else \"\"}'\n",
    "                            f'preProc('\n",
    "                            f'{\"R\" if config[\"R\"] else \"\"}'\n",
    "                            f'{\"T\" if config[\"T\"] else \"\"}'\n",
    "                            f'{\"Da\" if config[\"Da\"] else \"\"})'\n",
    "                            f'{(\" | Reduct(\" + str(polyReductionFactors) + \")\") if polyReductionFactors > 0 else \"\"}'\n",
    "                            f' ---', \n",
    "                            end=\"\"\n",
    "                        )\n",
    "\n",
    "                                                \n",
    "                        \n",
    "                        if polyReductionFactors > 0:\n",
    "                            X_trainS, X_testS, effects, powers = perform_feature_reduction(\n",
    "                                X_trainS, X_testS, model, polyReductionFactors, regressor, powers, Y_train\n",
    "                            )\n",
    "                                                \n",
    "                        y_pred, eval_data = evalData(pipeline, out_vars, np.array(pd.DataFrame(X_test.BL_Speed)), X_testS, Y_test )\n",
    "                                                    \n",
    "                        test_data = {\"type\"                 : \"Test_Data\", \n",
    "                                    \"regressor\"             : regressor,\n",
    "                                    \"preprocess_params\"     : params,\n",
    "                                    \"interaction_degree\"    : interactionsDegree, \n",
    "                                    \"reduction_factors\"     : polyReductionFactors,\n",
    "                                    \"test_param\"            : test_param,\n",
    "                                    \"training_size\"         : trainingSize\n",
    "                                    }\n",
    "                        test_data.update(eval_data)\n",
    "                        test_data[\"fit_time\"] = fitTime\n",
    "                                                                    \n",
    "                        metricsTest.append(test_data)\n",
    "                                                                \n",
    "                    metricsDf = pd.DataFrame(metricsTest)\n",
    "                    \n",
    "                    summary = {}                    \n",
    "                    for col in metricsDf.columns:                                                                      \n",
    "                        if np.issubdtype(metricsDf[col].dtype, np.number):                            \n",
    "                            summary[col + '_mean'] = metricsDf[col].mean()\n",
    "                            summary[col + '_std']  = metricsDf[col].std()\n",
    "                            \n",
    "                            if col.find('MAE') != -1 or col.find('RMSE') != -1:                                \n",
    "                                bt_ci = bootstrap_ci(metricsDf, col)\n",
    "                                summary[col + '_bs_ci_low']  = bt_ci[0]\n",
    "                                summary[col + '_bs_ci_up']  = bt_ci[1]\n",
    "                        else:                            \n",
    "                            summary[col] = metricsDf[col][0]\n",
    "                                                            \n",
    "                    print(f'\\nMAE: {summary[\"MAE_mean\"]:.3f} CI({summary[\"MAE_bs_ci_low\"]:.3f}, {summary[\"MAE_bs_ci_up\"]:.3f})' )                                       \n",
    "                    print(f'MAPE: {summary[\"MAPE_mean\"]:.3f}')                  \n",
    "                    print(f'Fit/Pred: {summary[\"fit_time_mean\"]:.3f} [s]' , end=\"\")\n",
    "                    print(f' / {summary[\"pred_time_mean\"]:.3f} [ms]\\n' )\n",
    "                    \n",
    "                                                            \n",
    "                    metricsSummary.append(summary)\n",
    "        \n",
    "                                                        \n",
    "summaryMetricDf = pd.DataFrame(metricsSummary)\n",
    "regressor_names = \"_\"\n",
    "for reg in models_config['regressors']:\n",
    "    regressor_names += reg + \"_\"\n",
    "    \n",
    "summaryMetricDf.to_csv(  \".\\Output\\Summary_\" + runTag + \"_\" + rangeType + regressor_names + str(models_config['folds'])  + \".csv\",index=False, header=True, mode='w')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "b_ace_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
