{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc38d15a",
   "metadata": {},
   "source": [
    "# WEZ Model Generation\n",
    "This notebook implements the pipeline for Weapon Engagement Zone (WEZ) model generation from the paper:\n",
    "\n",
    "Optimized Prediction of Weapon Effectiveness in BVR Air Combat Scenarios Using Enhanced Regression Models\n",
    "\n",
    "\n",
    "## Objectives\n",
    "- Develop and evaluate WEZ models using data from experiments.\n",
    "- Compare the performance of multiple regression techniques.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6586440",
   "metadata": {},
   "source": [
    "## Load the required Libraries and Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c97e6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "import itertools\n",
    "import time\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, PolynomialFeatures\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_squared_log_error \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet \n",
    "\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import  RandomForestRegressor\n",
    "\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\n",
    "from sklearn.gaussian_process.kernels import DotProduct, WhiteKernel\n",
    "\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error  \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def prepareDataFromASA(fileName, R = True,\\\n",
    "                        Da = True, size = -1,  \\\n",
    "                        T = True, multiObj = False, rangeType = \"WEZ\"):\n",
    "        \n",
    "    fulldataDf = pd.read_csv(fileName)   \n",
    "    \n",
    "    if size > 0:\n",
    "        fulldataDf = fulldataDf.sample(size)\n",
    "        \n",
    "    dataDf = fulldataDf[['BL_Speed', 'RD_Speed', 'rad', 'RD_Hdg', 'BL_Alt', 'RD_Alt']]\n",
    "    \n",
    "    if not multiObj:\n",
    "        dataDf[rangeType] = fulldataDf[rangeType].replace(-1,0)        \n",
    "        dataDf = dataDf[dataDf[rangeType] >= 2] \n",
    "    else:\n",
    "        dataDf['RNez'] = fulldataDf['RNez'].replace(-1,0)                \n",
    "        dataDf['RMax'] = fulldataDf['RMax'].replace(-1,0)                \n",
    "        dataDf = dataDf[dataDf['RNez'] >= 2]         \n",
    "        dataDf = dataDf[dataDf['RMax'] >= 2] \n",
    "\n",
    "    \n",
    "    if Da:                \n",
    "        \n",
    "        dataDf_Arg = dataDf.copy()\n",
    "        dataDf_Arg['rad'] = dataDf_Arg.apply(lambda x: -1 * x.rad , axis=1)  \n",
    "        dataDf_Arg['RD_Hdg'] = dataDf_Arg.apply(lambda x: -1 * x.RD_Hdg , axis=1)         \n",
    "        dataDf = pd.concat([dataDf, dataDf_Arg], axis=0, ignore_index=True)        \n",
    "            \n",
    "    dataDf['diffAlt'] = dataDf.apply(lambda x: x.BL_Alt - x.RD_Alt, axis=1)      \n",
    "                \n",
    "    if R:        \n",
    "        dataDf['relRedHdg'] = dataDf.apply(lambda x: (x.RD_Hdg-x.rad) , axis=1) \n",
    "        if T:\n",
    "            dataDf['cosRel'] = dataDf.apply(lambda x: math.cos(x.relRedHdg*math.pi/180), axis=1)\n",
    "            dataDf['sinRel'] = dataDf.apply(lambda x: math.sin(x.relRedHdg*math.pi/180), axis=1) \n",
    "            dataDf = dataDf.drop(['relRedHdg'], axis=1)              \n",
    "    \n",
    "    else:     \n",
    "        dataDf['relRedHdg'] = dataDf.apply(lambda x: 0-x.RD_Hdg , axis=1)\n",
    "        if T:\n",
    "            dataDf['cosRel'] = dataDf.apply(lambda x: math.cos(x.relRedHdg*math.pi/180), axis=1)\n",
    "            dataDf['sinRel'] = dataDf.apply(lambda x: math.sin(x.relRedHdg*math.pi/180), axis=1)\n",
    "            dataDf['cosRel2'] = dataDf.apply(lambda x: math.cos(x.rad*math.pi/180), axis=1)\n",
    "            dataDf['sinRel2'] = dataDf.apply(lambda x: math.sin(x.rad*math.pi/180), axis=1)\n",
    "            dataDf = dataDf.drop(['relRedHdg'], axis=1)  \n",
    "            #dataDf = dataDf.drop(['rad'], axis =1)                                                          \n",
    "    \n",
    "    dataDf = dataDf.drop(['RD_Hdg'], axis =1)     \n",
    "    dataDf = dataDf.drop(['RD_Alt'], axis =1) \n",
    "        \n",
    "    return dataDf\n",
    "\n",
    "def split_train_test(X, Y, mode, fold, trainingSize, testSize, dataSplitRatio, DataSetTest=None):\n",
    "    \"\"\"\n",
    "    Splits the data into training and testing sets based on the mode.\n",
    "\n",
    "    Parameters:\n",
    "        X (pd.DataFrame): Features.\n",
    "        Y (pd.DataFrame): Target.\n",
    "        mode (str): Split mode (RandomSplit, AlternateTest, FixedTestSize).\n",
    "        fold (int): Current fold index.\n",
    "        trainingSize (int): Size of training data.\n",
    "        testSize (int): Size of testing data.\n",
    "        dataSplitRatio (float): Ratio for RandomSplit.\n",
    "        DataSetTest (pd.DataFrame, optional): Alternate test dataset.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (X_train, X_test, Y_train, Y_test)\n",
    "    \"\"\"\n",
    "    if mode == \"RandomSplit\":\n",
    "        return train_test_split(X, Y, test_size=dataSplitRatio, random_state=fold)\n",
    "    elif mode == \"AlternateTest\":\n",
    "        X_train = X[:trainingSize]\n",
    "        Y_train = Y[:trainingSize]\n",
    "        shuffled_test = shuffle(DataSetTest, random_state=fold)\n",
    "        X_test = shuffled_test.drop([\"maxRange\"], axis=1)[:600]\n",
    "        Y_test = shuffled_test.maxRange[:600]\n",
    "        return X_train, X_test, Y_train, Y_test\n",
    "    elif mode == \"FixedTestSize\":\n",
    "        return train_test_split(X, Y, test_size=testSize, train_size=trainingSize, random_state=fold)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported split mode: {mode}\")\n",
    "\n",
    "def get_regressor(name, fold, multi_obj=False):\n",
    "    \"\"\"\n",
    "    Returns the specified regression model with appropriate parameters.\n",
    "    \"\"\"\n",
    "    if name == \"MLP32\":\n",
    "        return MLPRegressor(random_state=fold, max_iter=500000, activation='tanh', hidden_layer_sizes=(32, 32))\n",
    "    elif name == \"MLP128\":\n",
    "        return MLPRegressor(random_state=fold, max_iter=500000, activation='tanh', hidden_layer_sizes=(128, 128))\n",
    "    elif name == \"MLP256\":\n",
    "        return MLPRegressor(random_state=fold, max_iter=500000, activation='tanh', hidden_layer_sizes=(256, 256))\n",
    "    elif name == \"Ridge\":\n",
    "        return Ridge(alpha=0.02, max_iter=500000)\n",
    "    elif name == \"Lasso\":\n",
    "        return Lasso(alpha=0.00025, max_iter=500000)\n",
    "    elif name == \"ElasticNet\":\n",
    "        return ElasticNet(alpha=0.00025, l1_ratio=0.5,  max_iter=500000)\n",
    "    elif name == \"RF\":\n",
    "        return RandomForestRegressor(n_estimators=50, max_depth=20, random_state=fold, n_jobs=10)\n",
    "    elif name == \"LinReg\":\n",
    "        return LinearRegression(n_jobs=15, fit_intercept=False)\n",
    "    elif name == \"SVR_Poly\":\n",
    "        svr = SVR(kernel=\"poly\", C=5000, gamma=\"auto\", degree=1, epsilon=0.1, max_iter=500000)\n",
    "        return MultiOutputRegressor(svr) if multi_obj else svr\n",
    "    elif name == \"SVR_RBF\":\n",
    "        svr = SVR(kernel=\"rbf\", C=5000, gamma=\"auto\", epsilon=0.1, max_iter=500000)\n",
    "        return MultiOutputRegressor(svr) if multi_obj else svr\n",
    "    elif name == \"SVR_Linear\":\n",
    "        svr = SVR(kernel=\"linear\", C=5000, gamma=\"auto\", epsilon=0.1, max_iter=500000)\n",
    "        return MultiOutputRegressor(svr) if multi_obj else svr\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown Model: {name}\")\n",
    "\n",
    "def perform_feature_reduction(X_trainS, X_testS, model, polyReductionFactors, regressor, powers, Y_train):\n",
    "    \"\"\"\n",
    "    Reduces features based on model coefficients.\n",
    "\n",
    "    Parameters:\n",
    "        X_trainS (pd.DataFrame): Training dataset with features.\n",
    "        X_testS (pd.DataFrame): Test dataset with features.\n",
    "        model: Trained model with accessible coefficients.\n",
    "        polyReductionFactors (int): Number of features to retain.\n",
    "        regressor (str): Type of regressor (e.g., \"Ridge\", \"Lasso\").\n",
    "        powers (np.ndarray): Powers of polynomial features.\n",
    "        Y_train (pd.DataFrame): Target variable for training.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (X_train_reduced, X_test_reduced, effects, updated_powers)\n",
    "    \"\"\"\n",
    "    effects = []\n",
    "\n",
    "    if polyReductionFactors > 0:\n",
    "        # Extract coefficients based on the model type\n",
    "        if regressor == \"Ridge\":\n",
    "            coefs = model.coef_[0]\n",
    "        elif regressor == \"Lasso\":\n",
    "            coefs = model.coef_\n",
    "        else:\n",
    "            print(f\"Error: Model {regressor} does not accept parameters reduction\")\n",
    "            exit(1)\n",
    "        \n",
    "        # Pair features with coefficients and sort by importance\n",
    "        coefsAux = [[X_trainS.columns[i], c] for i, c in enumerate(list(coefs))]\n",
    "        coefsAux = sorted(coefsAux, key=lambda x: -abs(x[1]))\n",
    "\n",
    "        if coefsAux:\n",
    "            # Identify insignificant features to drop\n",
    "            insig = [x[0] for x in coefsAux[polyReductionFactors:]]\n",
    "            totalCoefs = sum([abs(x[1]) for x in coefsAux])\n",
    "\n",
    "            # Record effects for the remaining features\n",
    "            dictEf = {\"total\": totalCoefs}\n",
    "            for x in coefsAux:\n",
    "                dictEf[x[0]] = x[1] / totalCoefs\n",
    "            effects.append(dictEf)\n",
    "\n",
    "            # Drop insignificant features\n",
    "            X_trainS = X_trainS.drop(insig, axis=1)\n",
    "            X_testS = X_testS.drop(insig, axis=1)\n",
    "\n",
    "            # Update powers\n",
    "            mask = np.ones(powers.shape[0], dtype=bool)\n",
    "            mask[insig] = False\n",
    "            powers = powers[mask]\n",
    "\n",
    "            # Refit the model on reduced features\n",
    "            model.fit(X_trainS, Y_train)\n",
    "\n",
    "            # Recompute coefficients and effects after reduction\n",
    "            if regressor == \"Ridge\":\n",
    "                coefs = model.coef_[0]\n",
    "            elif regressor == \"Lasso\":\n",
    "                coefs = model.coef_\n",
    "\n",
    "            coefsAux = [[X_trainS.columns[i], c] for i, c in enumerate(list(coefs))]\n",
    "            coefsAux = sorted(coefsAux, key=lambda x: -abs(x[1]))\n",
    "            totalCoefs = sum([abs(x[1]) for x in coefsAux])\n",
    "\n",
    "            dictEf = {\"total\": totalCoefs}\n",
    "            for x in coefsAux:\n",
    "                dictEf[x[0]] = x[1] / totalCoefs\n",
    "            effects.append(dictEf)\n",
    "        else:\n",
    "            print(\"Fail to Reduce Params\")\n",
    "            exit(1)\n",
    "\n",
    "    return X_trainS, X_testS, effects, powers\n",
    "\n",
    "def print_configuration_summary(rangeType, dataFile, testSplitMode, trainingSize, testSize, \n",
    "                                 dataSplitRatio, multi_obj, out_vars, models_config, data_preprocess, normalize):\n",
    "    \"\"\"\n",
    "    Prints a detailed summary of the experiment configuration.\n",
    "    \n",
    "    Parameters:        \n",
    "        rangeType (str): Range type for the experiment.\n",
    "        dataFile (str): Dataset file name.\n",
    "        testSplitMode (str): Mode of splitting the dataset.\n",
    "        trainingSize (int): Number of training samples.\n",
    "        testSize (int): Number of test samples.\n",
    "        dataSplitRatio (float): Ratio of data splitting for random split.\n",
    "        multi_obj (bool): Indicates if the task is multi-objective.\n",
    "        out_vars (list): Output variables for prediction.\n",
    "        models_config (dict): Model configurations.\n",
    "        data_preprocess (dict): Data preprocessing configurations.\n",
    "        normalize (bool): Whether all features should be normalized.        \n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"                Experiment Configuration Summary\")\n",
    "    print(\"=\"*50)    \n",
    "    print(f\"Range Type                 : {rangeType}\")\n",
    "    print(f\"Dataset File               : {dataFile}\")\n",
    "    print(f\"Test Split Mode            : {testSplitMode}\")\n",
    "    \n",
    "    if testSplitMode == \"RandomSplit\":\n",
    "        print(f\"Data Split Ratio           : {dataSplitRatio:.2f}\")\n",
    "    else:\n",
    "        print(f\"Training Set Size          : {trainingSize}\")\n",
    "        print(f\"Test Set Size              : {testSize}\")\n",
    "        \n",
    "    print(f\"Multi-Objective            : {multi_obj}\")\n",
    "    print(f\"Output Variables           : {', '.join(out_vars)}\")\n",
    "    print(\"\\nModel Configurations:\")\n",
    "    print(f\"  Interaction Degrees      : {models_config['interactionsDegrees']}\")\n",
    "    print(f\"  Reduction Factors        : {models_config['reductionsFactors']}\")\n",
    "    print(f\"  Number of Folds          : {models_config['folds']}\")\n",
    "    print(f\"  Selected Regressors      : {', '.join(models_config['regressors'])}\")\n",
    "    print(\"\\nPreprocessing Configurations:\")\n",
    "    for key, values in data_preprocess.items():\n",
    "        print(f\"  {key:5}: {values}\")\n",
    "    print(f\"\\nNormalize Features     : {normalize}\")    \n",
    "    print(\"=\"*50 + \"\\n\")\n",
    "\n",
    "def bootstrap_ci(data, metric, n_bootstrap=5000, max_iterations=1000, min_variation=0.00001):\n",
    "    bootstrap_samples = []\n",
    "    prev_ci_lower, prev_ci_upper = None, None\n",
    "    \n",
    "    for i in range(max_iterations):\n",
    "        bootstrap_sample = np.random.choice(data[metric], size=len(data), replace=True)\n",
    "        bootstrap_samples.append(np.mean(bootstrap_sample))\n",
    "        \n",
    "        ci_lower, ci_upper = np.percentile(bootstrap_samples, [2.5, 97.5])\n",
    "        \n",
    "        if prev_ci_lower is not None and prev_ci_upper is not None:\n",
    "            variation = max(abs(ci_lower - prev_ci_lower), abs(ci_upper - prev_ci_upper))\n",
    "            if variation < min_variation:\n",
    "                break\n",
    "        \n",
    "        prev_ci_lower, prev_ci_upper = ci_lower, ci_upper\n",
    "    \n",
    "    return (ci_lower, ci_upper)\n",
    "\n",
    "def evalData(regressor, output_vars, ref_vel, X, Y,  timeReps = 100):\n",
    "    \n",
    "    #Eval on Training set\n",
    "    start = time.time()\n",
    "    \n",
    "    for i in range(timeReps):\n",
    "        y_pred = regressor.predict(X)     \n",
    "    predTime = time.time() - start  \n",
    "    \n",
    "    eval_results = {}   \n",
    "    \n",
    "    for i, output_name in enumerate(output_vars):\n",
    "        \n",
    "        Y_item  = np.array(Y[output_name])                \n",
    "        \n",
    "        if len(output_vars) > 1:\n",
    "            y_pred_item = np.array(y_pred[:,i])\n",
    "        else:\n",
    "            y_pred_item = np.array(y_pred).flatten()\n",
    "                    \n",
    "        \n",
    "        predDiff = Y_item - y_pred_item        \n",
    "        maxError = max( abs(predDiff)) \n",
    "        \n",
    "        if isinstance(ref_vel, np.ndarray):                    \n",
    "            time_err = np.mean(abs((predDiff) / ref_vel))\n",
    "        else:\n",
    "            time_err = np.mean(abs((predDiff) / 550))\n",
    "            \n",
    "        rel_err =  np.mean(abs((predDiff) / Y_item))               \n",
    "        mae = mean_absolute_error(Y_item, y_pred_item)\n",
    "        rmse = math.sqrt(mean_squared_error(Y_item, y_pred_item)) \n",
    "        \n",
    "        eval_results.update({output_name + \"_MAE\" : mae, \n",
    "                             output_name + \"_RMSE\" : rmse,\n",
    "                             output_name + \"_time_err\": time_err,\n",
    "                             output_name + \"_relative_err\" : rel_err,                             \n",
    "                             output_name + \"_max_error\" :maxError})\n",
    "    \n",
    "    eval_results['MAE']  = mean_absolute_error(Y, y_pred)    \n",
    "    eval_results['RMSE'] = math.sqrt(mean_squared_error(Y, y_pred)) \n",
    "    eval_results['MAPE'] =  np.mean(abs((predDiff) / Y_item))   \n",
    "        \n",
    "    eval_results.update({\"pred_time\" : predTime/len(Y) * 1000 , \"eval_reps\" : timeReps} )\n",
    "\n",
    "    return (y_pred, eval_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36711a6b",
   "metadata": {},
   "source": [
    "---\n",
    "## Experiment Configuration\n",
    "\n",
    "This section defines all the parameters required for the experiment. \n",
    "\n",
    "### Key Sections:\n",
    "1. **Experiment Tag and Range Type**:   \n",
    "   - `rangeType`: Specifies the output range to be modeled. Options include:\n",
    "     - `RMax`: Maximum range.\n",
    "     - `RNez`: No Escape Zone range.\n",
    "     - `Wez`: Multi-Objective Model for both Ranges\n",
    "\n",
    "2. **Data Splitting Parameters**:\n",
    "   - `testSplitMode`: Determines how the dataset is divided into training and testing sets. Options:\n",
    "     - `FixedTestSize`: Fixed number of training and test samples.\n",
    "     - `RandomSplit`: Randomly splits data based on a specified ratio.\n",
    "     - `AlternateTest`: Uses an alternate dataset for testing.\n",
    "   - `trainingSize` and `testSize`: Define the sizes of training and test datasets (applicable for `FixedTestSize`).\n",
    "   - `dataSplitRatio`: Ratio for splitting data (used for `RandomSplit` mode).\n",
    "\n",
    "3. **Normalization**:\n",
    "   - If `normalize` is `True`, the features will be normalized (scaled) to improve model performance.\n",
    "\n",
    "4. **Model Configuration**:\n",
    "   - Includes options for:\n",
    "     - Polynomial interaction degrees (`interactionsDegrees`).\n",
    "     - Feature reduction factors (`reductionsFactors`).\n",
    "     - Number of folds for cross-validation (`folds`).\n",
    "     - List of regressors to evaluate (`regressors`).\n",
    "         - \"Lasso\", \"Ridge\", \"ElasticNet\", \"LinReg\",\\\n",
    "           \"MLP32\", \"MLP128\", \"MLP256\",\\\n",
    "            \"SVR_RBF\", \"SVR_Poly\", \"SVR_Linear\"\\\n",
    "            \"RF\"\n",
    "\n",
    "5. **Data Preprocessing Options**:\n",
    "   - Configures preprocessing:\n",
    "     - (R)  Adding relative red heading features (`relativeRedHdg`).\n",
    "     - (Da) Augmenting the dataset (`argumentation`).\n",
    "     - (T)  Applying sine and cosine transformations to angular features (`sinCos`).\n",
    "\n",
    "6. **Test Parameters**:\n",
    "   - Reserved for custom testing or advanced configurations.\n",
    "\n",
    "---\n",
    "\n",
    "### How to Use:\n",
    "\n",
    "1. Update the configuration values in the block below to customize your experiment settings.\n",
    "2. For list-based configuration parameters, you can specify multiple values to explore different configurations in a single run.\n",
    "3. After finalizing the configuration, proceed with the model training and evaluation steps.\n",
    "4. Partial results will be displayed in the notebook, while the complete results will be saved in the `Output` folder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "affde406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "                Experiment Configuration Summary\n",
      "==================================================\n",
      "Range Type                 : RMax\n",
      "Dataset File               : RandomExperiment_1000_RMAX.csv\n",
      "Test Split Mode            : FixedTestSize\n",
      "Training Set Size          : 700\n",
      "Test Set Size              : 200\n",
      "Multi-Objective            : False\n",
      "Output Variables           : RMax\n",
      "\n",
      "Model Configurations:\n",
      "  Interaction Degrees      : [3, 4, 5]\n",
      "  Reduction Factors        : [100]\n",
      "  Number of Folds          : 5\n",
      "  Selected Regressors      : Lasso, Ridge\n",
      "\n",
      "Preprocessing Configurations:\n",
      "  R    : [True]\n",
      "  T    : [True]\n",
      "  Da   : [True]\n",
      "\n",
      "Normalize Features     : True\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Experiment identification\n",
    "runTag = \"Test01\"\n",
    "\n",
    "# Range Type\n",
    "rangeType = \"RMax\"  # Specifies the type of output range to model (e.g., \"RMax\", \"RNez\", \"Wez\").\n",
    "\n",
    "# Data Splitting Configuration\n",
    "testSplitMode = \"FixedTestSize\" # Mode of splitting the data:\n",
    "                                # - \"FixedTestSize\": Fixed training and test sizes.\n",
    "                                # - \"RandomSplit\": Random split with a specified ratio.\n",
    "                                # - \"AlternateTest\": Use alternate dataset for testing.\n",
    "\n",
    "trainingSize = 700               # Number of samples in the training dataset (applicable for FixedTestSize).\n",
    "testSize = 200                   # Number of samples in the testing dataset (applicable for FixedTestSize).\n",
    "dataSplitRatio = 0.20            # Ratio for splitting data (applicable for RandomSplit).\n",
    "\n",
    "# Normalization Flag\n",
    "normalize = True  # Whether to normalize all features (MinMaxScaler or StandardScaler can be used later).\n",
    "\n",
    "# Model Configuration\n",
    "models_config = { \n",
    "    'interactionsDegrees': [3,4,5],             # Polynomial interaction degrees to explore.\n",
    "    'reductionsFactors': [100],             # Number of features to retain after reduction.\n",
    "    'folds': 5,                             # Number of folds for cross-validation.\n",
    "    'regressors': [\"Lasso\", \"Ridge\"],       # List of regression models to evaluate. Examples:\n",
    "                                 \n",
    "}\n",
    "\n",
    "# Data Preprocessing Options\n",
    "data_preprocess = {        \n",
    "    'R' :  [True],   # Whether to include relative heading \n",
    "    'T' :  [True],   # Whether to include sine and cosine transformations of angular data\n",
    "    'Da':  [True],   # Whether to augment the dataset\n",
    "} \n",
    "\n",
    "# Test Parameters\n",
    "test_params = [-1]  # Additional parameters to pass for testing specific configurations\n",
    "\n",
    "if rangeType == \"RMax\":    \n",
    "    dataFile = \"RandomExperiment_1000_RMAX.csv\"     \n",
    "    multi_obj = False\n",
    "    out_vars = ['RMax']\n",
    "elif rangeType == \"RNez\":\n",
    "    dataFile = \"RandomExperiment_1000_NEZ.csv\"     \n",
    "    multi_obj = False\n",
    "    out_vars = ['RNez']\n",
    "elif rangeType == \"Wez\":\n",
    "    dataFile = \"RandomExperiment_1000_WEZ.csv\"     \n",
    "    multi_obj = True\n",
    "    out_vars = ['RNez','RMax']\n",
    "\n",
    "# Print summary of configurations\n",
    "print_configuration_summary(    \n",
    "    rangeType=rangeType,\n",
    "    dataFile=dataFile,\n",
    "    testSplitMode=testSplitMode,\n",
    "    trainingSize=trainingSize,\n",
    "    testSize=testSize,\n",
    "    dataSplitRatio=dataSplitRatio,\n",
    "    multi_obj=multi_obj,\n",
    "    out_vars=out_vars,\n",
    "    models_config=models_config,\n",
    "    data_preprocess=data_preprocess,\n",
    "    normalize=normalize,    \n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1815f3d3",
   "metadata": {},
   "source": [
    "---\n",
    "## Run the Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b967861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- (5/5) RMax | Lasso | IntDeg(3) | preProc(RTDa) | Reduct(100) ---\n",
      "MAE: 0.413 CI(0.396, 0.433)\n",
      "MAPE: 0.036\n",
      "Fit/Pred: 0.109 [s] / 0.441 [ms]\n",
      "\n",
      "--- (5/5) RMax | Lasso | IntDeg(4) | preProc(RTDa) | Reduct(100) ---\n",
      "MAE: 0.289 CI(0.275, 0.302)\n",
      "MAPE: 0.025\n",
      "Fit/Pred: 0.323 [s] / 0.415 [ms]\n",
      "\n",
      "--- (5/5) RMax | Lasso | IntDeg(5) | preProc(RTDa) | Reduct(100) ---\n",
      "MAE: 0.245 CI(0.225, 0.258)\n",
      "MAPE: 0.020\n",
      "Fit/Pred: 0.533 [s] / 0.422 [ms]\n",
      "\n",
      "--- (5/5) RMax | Ridge | IntDeg(3) | preProc(RTDa) | Reduct(100) ---\n",
      "MAE: 0.416 CI(0.394, 0.436)\n",
      "MAPE: 0.036\n",
      "Fit/Pred: 0.002 [s] / 0.394 [ms]\n",
      "\n",
      "--- (5/5) RMax | Ridge | IntDeg(4) | preProc(RTDa) | Reduct(100) ---\n",
      "MAE: 0.289 CI(0.272, 0.304)\n",
      "MAPE: 0.025\n",
      "Fit/Pred: 0.054 [s] / 0.426 [ms]\n",
      "\n",
      "--- (5/5) RMax | Ridge | IntDeg(5) | preProc(RTDa) | Reduct(100) ---\n",
      "MAE: 0.318 CI(0.320, 0.320)\n",
      "MAPE: 0.026\n",
      "Fit/Pred: 0.109 [s] / 0.402 [ms]\n",
      "\n",
      "Summary Results saved to .\\Output\\Summary_Test01_RMax_Lasso_Ridge_5.csv\n"
     ]
    }
   ],
   "source": [
    "#Run the experiments according to the specified configurations\n",
    "metricsSummary = []\n",
    "\n",
    "proccess_combinations = list(itertools.product(*data_preprocess.values()))\n",
    "\n",
    "for params in proccess_combinations:\n",
    "    \n",
    "    config = dict(zip(data_preprocess.keys(), params))        \n",
    "    dataSet = prepareDataFromASA('./Data/' + dataFile, multiObj=multi_obj, rangeType = rangeType, **config)        \n",
    "    \n",
    "    for regressor in models_config['regressors']:       \n",
    "        for interactionsDegree in models_config['interactionsDegrees']:\n",
    "            for polyReductionFactors in models_config['reductionsFactors']:                \n",
    "                for it, test_param in enumerate(test_params):\n",
    "                                    \n",
    "                    metricsTest = []                    \n",
    "                    \n",
    "                    for fold in range(models_config['folds']):\n",
    "                        \n",
    "                        if not multi_obj:\n",
    "                            X = dataSet.drop([rangeType], axis=1)\n",
    "                            Y = dataSet[[rangeType]]\n",
    "                        else:\n",
    "                            X = dataSet.drop([\"RNez\", \"RMax\"], axis=1)\n",
    "                            Y = dataSet[[\"RNez\", \"RMax\"]]                                                                            \n",
    "                        \n",
    "                        \n",
    "                        X_train, X_test, Y_train, Y_test = split_train_test(\n",
    "                            X, Y, testSplitMode, fold, trainingSize, testSize, dataSplitRatio\n",
    "                        )                       \n",
    "                        \n",
    "                        X_trainS = X_train                    \n",
    "                        X_testS = X_test                    \n",
    "                                                                                    \n",
    "                        # Create interaction terms (interaction of each regressor pair + polynomial)                        \n",
    "                        if interactionsDegree > 1:\n",
    "                            if regressor == \"LinReg\" or regressor == \"Lasso\" or regressor == \"Ridge\" or regressor == \"ElasticNet\":                            \n",
    "                                interaction = PolynomialFeatures(degree=interactionsDegree, include_bias=False, interaction_only=False)                                                  \n",
    "                                X_trainS = pd.DataFrame(interaction.fit_transform(X_trainS), columns=interaction.get_feature_names_out(input_features=list(map(str,list(X_trainS.columns)))))   \n",
    "                                X_testS = pd.DataFrame(interaction.fit_transform(X_testS), columns=interaction.get_feature_names_out(input_features=list(map(str,list(X_testS.columns)))))\n",
    "                                powers = interaction.powers_\n",
    "                                cols = X_trainS.columns                                                           \n",
    "\n",
    "                        if normalize:\n",
    "                            #scaler = StandardScaler()  \n",
    "                            scaler = MinMaxScaler()\n",
    "                            scaler.fit_transform(X_trainS)                            \n",
    "                            X_trainS = scaler.transform(X_trainS)    \n",
    "                            X_testS = scaler.transform(X_testS)                                            \n",
    "                            X_trainS = pd.DataFrame(X_trainS)\n",
    "                            X_testS = pd.DataFrame(X_testS)\n",
    "                        else:\n",
    "                            X_trainS = pd.DataFrame(X_trainS.values)\n",
    "                            X_testS  = pd.DataFrame(X_testS.values)\n",
    "                                                                                                                            \n",
    "                        model = get_regressor(regressor, fold, multi_obj)                        \n",
    "                                \n",
    "                        pipeline = Pipeline([('model', model)])                        \n",
    "                        start = time.time()                                                            \n",
    "                        pipeline.fit(X_trainS,Y_train)                    \n",
    "                        fitTime = time.time() - start\n",
    "                        \n",
    "                        print(\n",
    "                            f'\\r--- ({fold+1}/{models_config[\"folds\"]}) {rangeType} | '\n",
    "                            f'{regressor} | '\n",
    "                            f'IntDeg({interactionsDegree}) | '                            \n",
    "                            f'{(\"TestParam(\" + str(test_param) + \") | \") if test_param != -1 else \"\"}'\n",
    "                            f'preProc('\n",
    "                            f'{\"R\" if config[\"R\"] else \"\"}'\n",
    "                            f'{\"T\" if config[\"T\"] else \"\"}'\n",
    "                            f'{\"Da\" if config[\"Da\"] else \"\"})'\n",
    "                            f'{(\" | Reduct(\" + str(polyReductionFactors) + \")\") if polyReductionFactors > 0 else \"\"}'\n",
    "                            f' ---', \n",
    "                            end=\"\"\n",
    "                        )\n",
    "\n",
    "                                                \n",
    "                        \n",
    "                        if polyReductionFactors > 0:\n",
    "                            X_trainS, X_testS, effects, powers = perform_feature_reduction(\n",
    "                                X_trainS, X_testS, model, polyReductionFactors, regressor, powers, Y_train\n",
    "                            )\n",
    "                                                \n",
    "                        y_pred, eval_data = evalData(pipeline, out_vars, np.array(pd.DataFrame(X_test.BL_Speed)), X_testS, Y_test )\n",
    "                                                    \n",
    "                        test_data = {\"type\"                 : \"Test_Data\", \n",
    "                                    \"regressor\"             : regressor,\n",
    "                                    \"preprocess_params\"     : params,\n",
    "                                    \"interaction_degree\"    : interactionsDegree, \n",
    "                                    \"reduction_factors\"     : polyReductionFactors,\n",
    "                                    \"test_param\"            : test_param,\n",
    "                                    \"training_size\"         : trainingSize\n",
    "                                    }\n",
    "                        test_data.update(eval_data)\n",
    "                        test_data[\"fit_time\"] = fitTime\n",
    "                                                                    \n",
    "                        metricsTest.append(test_data)\n",
    "                                                                \n",
    "                    metricsDf = pd.DataFrame(metricsTest)\n",
    "                    \n",
    "                    summary = {}                    \n",
    "                    for col in metricsDf.columns:                                                                      \n",
    "                        if np.issubdtype(metricsDf[col].dtype, np.number):                            \n",
    "                            summary[col + '_mean'] = metricsDf[col].mean()\n",
    "                            summary[col + '_std']  = metricsDf[col].std()\n",
    "                            \n",
    "                            if col.find('MAE') != -1 or col.find('RMSE') != -1:                                \n",
    "                                bt_ci = bootstrap_ci(metricsDf, col)\n",
    "                                summary[col + '_bs_ci_low']  = bt_ci[0]\n",
    "                                summary[col + '_bs_ci_up']  = bt_ci[1]\n",
    "                        else:                            \n",
    "                            summary[col] = metricsDf[col][0]\n",
    "                                                            \n",
    "                    print(f'\\nMAE: {summary[\"MAE_mean\"]:.3f} CI({summary[\"MAE_bs_ci_low\"]:.3f}, {summary[\"MAE_bs_ci_up\"]:.3f})' )                                       \n",
    "                    print(f'MAPE: {summary[\"MAPE_mean\"]:.3f}')                  \n",
    "                    print(f'Fit/Pred: {summary[\"fit_time_mean\"]:.3f} [s]' , end=\"\")\n",
    "                    print(f' / {summary[\"pred_time_mean\"]:.3f} [ms]\\n' )\n",
    "                    \n",
    "                                                            \n",
    "                    metricsSummary.append(summary)\n",
    "        \n",
    "                                                        \n",
    "summaryMetricDf = pd.DataFrame(metricsSummary)\n",
    "regressor_names = \"_\"\n",
    "for reg in models_config['regressors']:\n",
    "    regressor_names += reg + \"_\"\n",
    "    \n",
    "output_file = \".\\Output\\Summary_\" + runTag + \"_\" + rangeType + regressor_names + str(models_config['folds'])  + \".csv\"\n",
    "summaryMetricDf.to_csv( output_file ,index=False, header=True, mode='w')\n",
    "\n",
    "print( f'Summary Results saved to {output_file}' )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "b_ace_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
